{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_percentage_error,mean_absolute_error,root_mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "import shap\n",
    "\n",
    "\n",
    "\n",
    "scale_cols = [\n",
    "        'AVG temperature', 'AVG rain', 'AVG fr_rain', 'AVG snow', 'AVG ice', 'AVG snow_depth',\n",
    "        'AVG accumulated', 'AVG probability', 'AVG rate', 'AVG clouds', 'Physical capacity village level',\n",
    "        'Physical capacity village level for hotel', 'Physical capacity village level for comfort',\n",
    "        'Physical capacity village level for premium', 'Physical capacity village level for VIP', \n",
    "        'Rented villa nights before booking date on village level',\n",
    "        'Rented villa nights before booking date on village level for hotel',\n",
    "        'Rented villa nights before booking date on village level for comfort',\n",
    "        'Rented villa nights before booking date on village level for premium',\n",
    "        'Rented villa nights before booking date on village level for VIP',\n",
    "        'Cottage rent per person', 'Lagged Cancellation Amount','Lagged cancellation insurance Amount','Lagged travel insurance Amount',\n",
    "        'MIN temperature', 'MAX temperature', 'MIN rain', 'MAX rain',\n",
    "        'MIN fr_rain', 'MAX fr_rain', 'MIN snow', 'MAX snow', 'MIN ice', 'MAX ice', 'MIN snow_depth', \n",
    "        'MAX snow_depth', 'MIN accumulated', 'MAX accumulated', 'MIN probability', 'MAX probability',\n",
    "        'MIN rate', 'MAX rate'\n",
    "    ]\n",
    "weather_cols=['AVG temperature', 'AVG rain', 'AVG fr_rain', 'AVG snow', 'AVG ice', 'AVG snow_depth',\n",
    "        'AVG accumulated', 'AVG probability', 'AVG rate', 'AVG clouds','MIN temperature', 'MAX temperature', 'MIN rain', 'MAX rain',\n",
    "        'MIN fr_rain', 'MAX fr_rain', 'MIN snow', 'MAX snow', 'MIN ice', 'MAX ice', 'MIN snow_depth', \n",
    "        'MAX snow_depth', 'MIN accumulated', 'MAX accumulated', 'MIN probability', 'MAX probability',\n",
    "        'MIN rate', 'MAX rate']\n",
    "capacity_cols=[ 'Lagged Cancellation Amount','Lagged cancellation insurance Amount','Lagged travel insurance Amount',\n",
    "               'Physical capacity village level','Physical capacity village level for hotel', 'Physical capacity village level for comfort',\n",
    "            'Physical capacity village level for premium', 'Physical capacity village level for VIP', \n",
    "            'Rented villa nights before booking date on village level',\n",
    "            'Rented villa nights before booking date on village level for hotel',\n",
    "            'Rented villa nights before booking date on village level for comfort',\n",
    "            'Rented villa nights before booking date on village level for premium',\n",
    "            'Rented villa nights before booking date on village level for VIP',\n",
    "            'Cottage rent per person']\n",
    "cat_cols=['Holiday name', 'Leadtime','Booking day of week', 'Day of week visit',\n",
    "        'Booking month', 'Month visit', 'Booking day date', 'Day visit date']\n",
    "lag_cols=['Rented villa nights before booking date on village level',\n",
    "       'Rented villa nights before booking date on village level for hotel',\n",
    "       'Rented villa nights before booking date on village level for comfort',\n",
    "       'Rented villa nights before booking date on village level for premium',\n",
    "       'Rented villa nights before booking date on village level for VIP','Lagged Cancellation Amount', 'Lagged cancellation insurance Amount',\n",
    "       'Lagged travel insurance Amount','AVG temperature', 'AVG rain', 'AVG fr_rain', 'AVG snow', 'AVG ice', 'AVG snow_depth',\n",
    "        'AVG accumulated', 'AVG probability', 'AVG rate', 'AVG clouds','MIN temperature', 'MAX temperature', 'MIN rain', 'MAX rain',\n",
    "        'MIN fr_rain', 'MAX fr_rain', 'MIN snow', 'MAX snow', 'MIN ice', 'MAX ice', 'MIN snow_depth', \n",
    "        'MAX snow_depth', 'MIN accumulated', 'MAX accumulated', 'MIN probability', 'MAX probability',\n",
    "        'MIN rate', 'MAX rate']\n",
    "\n",
    "\n",
    "\n",
    "# Splitting data in train, test and validation\n",
    "def train_test_validation(df):\n",
    "    split_date = '2023-09-30'\n",
    "    split_date2 = '2022-10-01'\n",
    "    split_date3 = '2022-09-30'\n",
    "    train = df.loc[:split_date3]\n",
    "    validation = df.loc[split_date2:split_date]\n",
    "    test = df.loc[split_date:]\n",
    "\n",
    "    return train,test,validation\n",
    "\n",
    "#compares predicted and true values based on pandas describe\n",
    "#extreme argument indicates what deviation of prediction and true value is classified as extreme\n",
    "def comparison(y_test, y_pred, lead, compare, algo,X_test,extreme=0.2932751092707807):\n",
    "    \n",
    "    start_date= '2023-10-01'\n",
    "    end_date= '2024-09-02'\n",
    "\n",
    "    # Append new data if 'compare' already exists\n",
    "    new_data = pd.DataFrame({\n",
    "        'true': y_test,\n",
    "        'predicted': y_pred,\n",
    "        'Leadtime': lead,\n",
    "        'Model': algo,\n",
    "        'difference': y_test - y_pred  ,\n",
    "        'negative': y_pred < 0,\n",
    "        'extreme': (y_test - y_pred > extreme) | (y_test - y_pred < -extreme),\n",
    "        'extreme threshold':extreme,\n",
    "        'Date visit':X_test.index\n",
    "    })\n",
    "    \n",
    "    compare = pd.concat([compare, new_data], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    return compare\n",
    "#Fills missing values based on last observed value closest to date in specified limit, optionally can also fill with maximum value for that date\n",
    "#column1 is the column with missing values\n",
    "#column is the date column that the imputation is based on\n",
    "#days is the upper limit that is used for looking up past values\n",
    "def fill_values(df, column1, column2, days, maxi=False):\n",
    "    # Convert the date column to datetime\n",
    "    df[column2] = pd.to_datetime(df[column2], format='%d-%m-%Y', errors='raise')\n",
    "\n",
    "    # Get indices of NaN values in column1\n",
    "    na_indices = df[df[column1].isna()].index\n",
    "\n",
    "    # Iterate through the indices with NaN values\n",
    "    for index in na_indices:\n",
    "        filled = False  # Track if we filled the NaN\n",
    "        current_date = df.loc[index, column2]\n",
    "\n",
    "        # Get rows for the same date\n",
    "        same_date_rows = df[df[column2] == current_date]\n",
    "\n",
    "        if maxi:\n",
    "            # If maxi=True, fill with the max value from that day\n",
    "            max_value = same_date_rows[column1].max()\n",
    "            if not pd.isna(max_value):\n",
    "                df.loc[index, column1] = max_value\n",
    "                filled = True\n",
    "        else:\n",
    "            # Fill with the first non-NaN value from that day\n",
    "            for _, row in same_date_rows.iterrows():\n",
    "                if not pd.isna(row[column1]):\n",
    "                    df.loc[index, column1] = row[column1]\n",
    "                    filled = True\n",
    "                    break\n",
    "\n",
    "        # If not filled from the same date, check previous days\n",
    "        if not filled and days > 0:\n",
    "            for day in range(1, days + 1):\n",
    "                prev_date = current_date - pd.Timedelta(days=day)\n",
    "                prev_rows = df[df[column2] == prev_date]\n",
    "\n",
    "                if maxi:\n",
    "                    # Fill with max value from the previous date\n",
    "                    max_value = prev_rows[column1].max()\n",
    "                    if not pd.isna(max_value):\n",
    "                        df.loc[index, column1] = max_value\n",
    "                        filled = True\n",
    "                        break\n",
    "                else:\n",
    "                    # Fill with first non-NaN value from previous dates\n",
    "                    for _, row in prev_rows.iterrows():\n",
    "                        if not pd.isna(row[column1]):\n",
    "                            df.loc[index, column1] = row[column1]\n",
    "                            filled = True\n",
    "                            break\n",
    "                if filled:\n",
    "                    break\n",
    "        \n",
    "        # If no value was filled after checking the same and previous days\n",
    "        if not filled:\n",
    "            print(f\"NaN found at index {index} for date {df.loc[index, column2]} could not be filled with any values.\")\n",
    "\n",
    "    return df\n",
    "#Turns date visit, forecast dt iso, slice dt iso, and booking date into pandas date formats\n",
    "def date_format():\n",
    "    df['Date visit']=pd.to_datetime(df['Date visit'], format='%d-%m-%Y', errors='raise')\n",
    "    df['Booking date'] = pd.to_datetime(df[\"Booking date\"], format='%d-%m-%Y', errors='raise')\n",
    "    df['forecast dt iso'] = pd.to_datetime(df[\"forecast dt iso\"], format='%d-%m-%Y', errors='raise')\n",
    "    df['slice dt iso'] = pd.to_datetime(df[\"slice dt iso\"], format='%d-%m-%Y', errors='raise')\n",
    "#Creates leadtime, day of week, month features for booking date and date visit\n",
    "def feature_engineer():\n",
    "    df['Leadtime']=(df['Date visit'] - df['Booking date']).dt.days.astype(int)\n",
    "    df['Booking day of week']=df['Booking date'].dt.dayofweek\n",
    "    df['Day of week visit']=df['Date visit'].dt.dayofweek\n",
    "    df['Booking month']=df['Booking date'].dt.month\n",
    "    df['Month visit']=df['Date visit'].dt.month \n",
    "    df['Booking day date']=df['Booking date'].dt.day\n",
    "    df['Day visit date']=df['Date visit'].dt.day\n",
    "#Filters df for leadtimes between 0 and up to 16 days\n",
    "def leadfilter ():\n",
    "    #Filtering for leadtime matching the weather forecast: Between 0 and 16 days\n",
    "    df=df[df['Leadtime']>=0]\n",
    "    df=df[df['Leadtime']<=16]\n",
    "#Aggregated insurance counts are filled with 0, as nan means 0 for those columns\n",
    "def impute():\n",
    "    \n",
    "    df[['Cancellation amount','Cancellation insurance', 'Travel insurance']] = df[['Cancellation amount','Cancellation insurance', 'Travel insurance']].fillna(0)     \n",
    "# replaces commas with points and turns columns numeric\n",
    "def make_numeric():\n",
    "#Replace commas with points and turn object columns to numeric\n",
    "    cols = [\n",
    "        'MIN temperature', 'MAX temperature', 'AVG temperature',\n",
    "        'MIN rain', 'MAX rain', 'AVG rain',\n",
    "        'MIN fr_rain', 'MAX fr_rain', 'AVG fr_rain',\n",
    "        'MIN snow', 'MAX snow', 'AVG snow',\n",
    "        'MIN ice', 'MAX ice', 'AVG ice',\n",
    "        'MIN snow_depth', 'MAX snow_depth', 'AVG snow_depth',\n",
    "        'MIN accumulated', 'MAX accumulated', 'AVG accumulated',\n",
    "        'MIN probability', 'MAX probability', 'AVG probability',\n",
    "        'MIN rate', 'MAX rate', 'AVG rate',\n",
    "        'AVG clouds','Cottage rent per person','Cottage rent VIP per person',\n",
    "        'Cottage rent comfort per person','Cottage rent premium per person'\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    def replace_commas(x):\n",
    "        if isinstance(x, str):\n",
    "            return x.replace(',', '.')\n",
    "        return x\n",
    "\n",
    "    # Apply replacement to relevant columns\n",
    "    df[cols] = df[cols].apply(lambda col: col.map(replace_commas))\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='raise')\n",
    "\n",
    "# Function to propagate lagged values for a given test DataFrame and leadtime\n",
    "def propagate_lag_values(test, leadtime, lag_cols=lag_cols):\n",
    "    leadtime_values = test[test['Leadtime'] == leadtime][lag_cols]\n",
    "    \n",
    "    # Ensure dynamic alignment of values row-by-row\n",
    "    for col in lag_cols:\n",
    "        test[col] = test.index.map(leadtime_values[col].to_dict())\n",
    "    test = test[test['Leadtime'] != leadtime].copy()\n",
    "    return test\n",
    "\n",
    "\n",
    "filepath='C:\\\\Users\\\\lsugg\\\\OneDrive - Pierre & Vacances - Centerparcs Group\\\\Desktop\\\\Sixth try.csv'\n",
    "data=pd.read_csv(filepath,delimiter=';',low_memory=False)\n",
    "df=pd.DataFrame(data)\n",
    "#Some observations that are based on calculations in tableau have the '#DIV/0' adn get replaced with na\n",
    "df.replace('#DIV/0', np.nan, inplace=True)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "\n",
    "date_format()\n",
    "feature_engineer()\n",
    "#df['Occupancy'] = df['Rented villa nights in date visit'] / df['Physical capacity village level']\n",
    "# Filling missing holiday names based on holiday names for the same date visit\n",
    "df = fill_values(df, 'Holiday name', 'Date visit', 0)\n",
    "#Turning Holiday name categorical\n",
    "print(np.unique(df['Holiday name']))\n",
    "holiday_list = ['Autumn H', 'Christ_NY H', 'Core Summer H', 'Easter May H', 'Spring H', 'Summer H']\n",
    "df['Holiday name'] = np.where(df['Holiday name'].isin(holiday_list), 1, 0)\n",
    "\n",
    "\n",
    "#No forecast for this time\n",
    "df = df[~(df['Date visit'] >= '2024-09-17')]\n",
    "#Park was closed from 19.11.2018 until 06.12.2018\n",
    "df = df[~((df['Date visit'] >= '2018-11-19') & (df['Date visit'] <= '2018-12-06'))]\n",
    "ddf=df.copy()\n",
    "df = df.sort_values(by=['Date visit', 'Booking date'], ascending=[True, True]).set_index('Date visit') \n",
    "impute()\n",
    "make_numeric()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dropping observations without weather data\n",
    "df=df.dropna(subset='forecast dt iso')\n",
    "\n",
    "# Split overview\n",
    "split_date = '2023-09-30' #end of training-validation data\n",
    "split_date2 = '2022-10-01' # start of validation data\n",
    "split_date3 = '2022-09-30' # end of training data\n",
    "#5% na values for renting price\n",
    "# Filling NA with training median to avoid data leakage\n",
    "train_median = df['Cottage rent per person'].loc[:split_date3].median()\n",
    "df['Cottage rent per person'] = df['Cottage rent per person'].fillna(train_median)\n",
    "#Dropping temp columns\n",
    "df=df.drop(['Rented villa nights',\n",
    "       'Rented villa nights hotel', 'Rented villa nights comfort',\n",
    "       'Rented villa nights premium', 'Rented villa nights VIP','Booking date', 'forecast dt iso', 'slice dt iso'],axis=1)\n",
    "#Dropping all columns with missing values\n",
    "df=df.dropna(axis=1)\n",
    "#columns used for preprocessing in tableau\n",
    "df=df.drop(['Rented villa nights in date visit for VIP1',\n",
    "       'Rented villa nights in date visit for VIP',\n",
    "       'Rented villa nights in date visit for premium1',\n",
    "       'Rented villa nights in date visit for premium',\n",
    "       'Rented villa nights in date visit for comfort1',\n",
    "       'Rented villa nights in date visit for comfort',\n",
    "       'Rented villa nights in date visit for hotel',\n",
    "       'Rented villa nights in date visit1',\n",
    "       'Rented villa nights in date visit'],axis=1)\n",
    "def create_lag():\n",
    "\n",
    "       # Create a lagged version of 'Cancellation amount' by shifting within groups\n",
    "       df['Lagged Cancellation Amount'] = df.groupby(df.index)['Cancellation amount'].shift(1)\n",
    "       # Compute the running sum of the lagged values\n",
    "       df['Lagged Cancellation Amount'] = df.groupby(df.index)['Lagged Cancellation Amount'].cumsum().fillna(0)\n",
    "\n",
    "       # Create a lagged version of 'cancellation insurance amount' by shifting within groups\n",
    "       df['Lagged cancellation insurance Amount'] = df.groupby(df.index)['Cancellation insurance'].shift(1)\n",
    "       # Compute the running sum of the lagged values\n",
    "       df['Lagged cancellation insurance Amount'] = df.groupby(df.index)['Lagged cancellation insurance Amount'].cumsum().fillna(0)\n",
    "\n",
    "       # Create a lagged version of 'travel insurance amount' by shifting within groups\n",
    "       df['Lagged travel insurance Amount'] = df.groupby(df.index)['Travel insurance'].shift(1)\n",
    "       # Compute the running sum of the lagged values\n",
    "       df['Lagged travel insurance Amount'] = df.groupby(df.index)['Lagged travel insurance Amount'].cumsum().fillna(0)\n",
    "       for col in weather_cols:\n",
    "              df[col]=df.groupby(df.index)[col].shift(1)\n",
    "create_lag()        \n",
    "\n",
    "df['Occupancy']=df[df['Leadtime']==0]['Rented villa nights before booking date on village level']/df[df['Leadtime']==0]['Physical capacity village level']\n",
    "print(df[['Leadtime', 'Cancellation amount','Lagged Cancellation Amount','Cancellation insurance','Lagged cancellation insurance Amount','Travel insurance','Lagged travel insurance Amount']].loc['2023-08-04'].head(17))\n",
    "#Dropping features after lagged features have been created\n",
    "df=df.drop(['Cancellation amount',\t'Cancellation insurance',\t'Travel insurance'],axis=1)\n",
    "#Filter rows where 'Occupancy' is na\n",
    "na_rows = df[df['Occupancy'].isna()]\n",
    "#As missing rows are close to the end of provided data, there is no 0 lead time, thus the 17 rows are dropped\n",
    "# Display the rows\n",
    "print(na_rows[['Leadtime','Occupancy']].head(17))\n",
    "df=df.dropna()\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corr()\n",
    "df_corr=df_corr.drop(['Physical capacity village level',\n",
    "       'Physical capacity village level for hotel',\n",
    "       'Physical capacity village level for comfort',\n",
    "       'Physical capacity village level for premium',\n",
    "       'Physical capacity village level for VIP'],axis=1)\n",
    "df_corr=df_corr.drop(['Physical capacity village level',\n",
    "       'Physical capacity village level for hotel',\n",
    "       'Physical capacity village level for comfort',\n",
    "       'Physical capacity village level for premium',\n",
    "       'Physical capacity village level for VIP'],axis=0)\n",
    "useful_df = pd.DataFrame()\n",
    "\n",
    "for row, col in zip(df_corr.index, df_corr.columns[::-1]):\n",
    "    if row in weather_cols and col in weather_cols:\n",
    "        continue\n",
    "    elif row in capacity_cols and col in capacity_cols:\n",
    "        continue\n",
    "    elif row == col:\n",
    "        continue\n",
    "    else:\n",
    "        # Extract the correlation value\n",
    "        new_row = pd.DataFrame([df_corr.loc[row, col]], columns=[f'{row}-{col}'])\n",
    "        useful_df = pd.concat([useful_df, new_row], axis=1)\n",
    "\n",
    "#transposing the final df to have rows as correlations\n",
    "useful_df = useful_df.transpose()\n",
    "useful_df['Correlation']=useful_df[0].copy()\n",
    "useful_df=useful_df.drop([0],axis=1)\n",
    "useful_df.sort_values(by=['Correlation'])\n",
    "useful_df=useful_df.dropna()\n",
    "useful_df\n",
    "plt.figure(figsize=(6,10))\n",
    "plt.barh(useful_df.index, useful_df.iloc[:, 0])  \n",
    "plt.xticks(rotation=90)  \n",
    "\n",
    "plt.ylabel('Correlation Pairs')  \n",
    "plt.xlabel('Correlation Value')  \n",
    "plt.title('Correlation Values Between Features')  \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr=df.corr()\n",
    "df_corr=df_corr.sort_values(by=['Occupancy'])\n",
    "plt.figure(figsize=(20,8))\n",
    "bars = plt.bar(df_corr.index, df_corr['Occupancy'])\n",
    "\n",
    "# Add annotations (index names) on top of each bar\n",
    "\n",
    "plt.axhline(0.2,color='r')\n",
    "plt.axhline(-0.2,color='r')\n",
    "# Set labels and title\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Correlation Values')\n",
    "plt.title('Correlation of \"Occupancy\"')\n",
    "\n",
    "# Display the plot\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels if needed\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon14 = df[df['Leadtime'] <= 15].copy()\n",
    "horizon7 = df[df['Leadtime'] <= 8].copy()\n",
    "horizon5 = df[df['Leadtime'] <= 6].copy()\n",
    "horizon1 = df[df['Leadtime'] <= 2].copy()\n",
    "horizon14 = propagate_lag_values(horizon14, 15).dropna()\n",
    "horizon7 = propagate_lag_values(horizon7, 8).dropna()\n",
    "horizon5 = propagate_lag_values(horizon5, 6).dropna()\n",
    "horizon1 = propagate_lag_values(horizon1, 2).dropna()\n",
    "frames=[horizon14,horizon7,horizon5,horizon1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Prepped_data_occupancy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(pd.read_csv('C:\\\\Users\\\\lsugg\\OneDrive - Pierre & Vacances - Centerparcs Group\\\\Desktop\\\\Thesis\\\\Prepped_data_occupancy.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define lead colors for visualization\n",
    "lead_colors = {1: 'blue'}\n",
    "\n",
    "# Plotting target variable\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# Loop through unique lead times and plot each series\n",
    "for lead in [1]:\n",
    "    temp_df = df[df['Leadtime'] == lead]\n",
    "    print(temp_df['Occupancy'].describe())\n",
    "    # Group by date and calculate mean of 'Rented villa nights to come' per date\n",
    "    mean_series = temp_df.groupby(temp_df.index)['Occupancy'].mean()\n",
    "    plt.plot(temp_df['Occupancy'], color=lead_colors.get(lead, 'black'))\n",
    "\n",
    "# Add legend and adjust layout\n",
    "plt.axhline(temp_df['Occupancy'].mean(),label='Mean')\n",
    "plt.axhline(temp_df['Occupancy'].median(),label='Median',color='r')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Date visit\")\n",
    "plt.ylabel(\"Occupancy\")\n",
    "plt.title(\"Occupancy distribution\")\n",
    "plt.tight_layout()  # Adjust layout to make room for the legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data in train, test and validation\n",
    "split_date = '2023-09-30' #end of training-validation data\n",
    "split_date2 = '2022-10-01' # start of validation data\n",
    "split_date3 = '2022-09-30' # end of training data\n",
    "\n",
    "\n",
    "def scree_separate(train):\n",
    "    leads = [1, 5, 7, 14]\n",
    "\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    frame = train.copy()\n",
    "    lead=frame['Leadtime'].max()\n",
    "    #Scaling the training data for the specified columns\n",
    "    frame_scaled = scaler.fit_transform(frame[scale_cols])\n",
    "    frame_scaled = pd.DataFrame(frame_scaled, columns=scale_cols, index=frame.index)\n",
    "    \n",
    "    #Applying PCA to weather and capacity features\n",
    "    pca_weather = PCA(n_components=10)\n",
    "    pca_capacity = PCA(n_components=10)\n",
    "\n",
    "    train_weather = pd.DataFrame(\n",
    "        pca_weather.fit_transform(frame_scaled[weather_cols]),\n",
    "        columns=[f'PC_weather_{i+1}' for i in range(10)],\n",
    "        index=frame.index\n",
    "    )\n",
    "    \n",
    "    train_capacity = pd.DataFrame(\n",
    "        pca_capacity.fit_transform(frame_scaled[capacity_cols]),\n",
    "        columns=[f'PC_capacity_{i+1}' for i in range(10)],\n",
    "        index=frame.index\n",
    "    )\n",
    "    \n",
    "    #Combining PCA results\n",
    "    pca_separate = pd.concat([train_weather, train_capacity], axis=1)\n",
    "    \n",
    "    #Plotting the scree plots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    #Scree plot for weather features\n",
    "    axes[0].plot(range(1, 11), pca_weather.explained_variance_ratio_, marker='o', label='Weather')\n",
    "    axes[0].set_title(f'Scree Plot for Weather PCA (Leadtime {lead})')\n",
    "    axes[0].set_xlabel('Principal Component')\n",
    "    axes[0].set_ylabel('Explained Variance Ratio')\n",
    "    axes[0].grid()\n",
    "    axes[0].legend()\n",
    "\n",
    "    #Scree plot for capacity features\n",
    "    axes[1].plot(range(1, 11), pca_capacity.explained_variance_ratio_, marker='o', label='Capacity')\n",
    "    axes[1].set_title(f'Scree Plot for Capacity PCA (Leadtime {lead})')\n",
    "    axes[1].set_xlabel('Principal Component')\n",
    "    axes[1].set_ylabel('Explained Variance Ratio')\n",
    "    axes[1].grid()\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def scree_blended (train):\n",
    "    leads=[1,5,7,1]\n",
    "    \n",
    "    scaler=RobustScaler()\n",
    "    frame = train.copy()\n",
    "    lead=frame['Leadtime'].max()\n",
    "    \n",
    "    train_scaled = scaler.fit_transform(frame[scale_cols])\n",
    "\n",
    "    #PCA\n",
    "    pca_all = PCA(n_components=10)\n",
    "\n",
    "    #Fitting PCA on the entire scaled dataset\n",
    "    pca_all.fit(train_scaled)\n",
    "\n",
    "    #Creating a df for the explained variance ratio\n",
    "    explained_variance_ratio = pd.DataFrame(pca_all.explained_variance_ratio_, \n",
    "                                            columns=['Explained Variance Ratio'])\n",
    "\n",
    "    #Plotting the scree plot \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, 11), explained_variance_ratio.values, marker='o')\n",
    "    plt.title(f'Scree Plot for PCA on All Scaled Columns with Leadtime {lead}')\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.ylabel('Explained Variance Ratio')\n",
    "    plt.xticks(range(1, 11))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "for frame in frames: \n",
    "    train = frame.loc[:split_date3]\n",
    "\n",
    "    validation = frame.loc[split_date2:split_date]\n",
    "    test = frame.loc[split_date:]\n",
    "    scree_separate(train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in frames: \n",
    "    train = frame.loc[:split_date3]\n",
    "\n",
    "    validation = frame.loc[split_date2:split_date]\n",
    "    test = frame.loc[split_date:]\n",
    "    scree_blended(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive model uses prior year to predict test year\n",
    "#\n",
    "def naive_model(split_date = '2023-10-01'):\n",
    "        #point forecast\n",
    "    ddf=df.copy()\n",
    "    ddf=ddf.drop(index='2024-02-29')\n",
    "    lead16=ddf[ddf['Leadtime']<=14]\n",
    "    lead7=ddf[ddf['Leadtime']<=7]\n",
    "    lead5=ddf[ddf['Leadtime']<=5]\n",
    "    lead1=ddf[ddf['Leadtime']<=1]\n",
    "    maes={}\n",
    "    compare = pd.DataFrame(columns=['true','predicted','Leadtime','difference','negative','Date visit','extreme'])\n",
    "\n",
    "    frames=[lead16, lead7, lead5, lead1]\n",
    "    for frame in frames:\n",
    "        # Perform the time-based split\n",
    "        #scale(frame,'Occupancy')\n",
    "        lead=frame['Leadtime'].max()\n",
    "        \n",
    "        split_date = '2023-10-01'\n",
    "        #remove leap year date\n",
    "        \n",
    "        test = frame.loc[split_date:]\n",
    "        test=test[['Occupancy','Leadtime']]\n",
    "        end='2024-09-01'\n",
    "        test=test.loc[:end]\n",
    "        split_date2 = '2022-10-01'\n",
    "        train_naive=frame.loc[split_date2:]\n",
    "        #Because that is where the test data stops\n",
    "        split_date3='2023-09-01'\n",
    "        train_naive=train_naive.loc[:split_date3]\n",
    "        train_naive=train_naive[['Occupancy','Leadtime']]\n",
    "        #train_naive now contains only the dates 1 year prior to the test data\n",
    "\n",
    "        naive_pred=train_naive['Occupancy'].reset_index(drop=True)\n",
    "        actual=test['Occupancy'].reset_index(drop=True)\n",
    "\n",
    "\n",
    "        # Calculate metrics\n",
    "        mape= np.round(mean_absolute_percentage_error(actual, naive_pred), 3)\n",
    "        mae = np.round(mean_absolute_error(actual, naive_pred), 3)\n",
    "        rmse = np.round(root_mean_squared_error(actual, naive_pred), 3)\n",
    "        \n",
    "        \n",
    "        compare=comparison(actual,naive_pred,lead,compare,\"Naive\",test)\n",
    "    \n",
    "        maes.update({lead.astype(str):mae})\n",
    "    print(f'Naive forecast from previous year')\n",
    "    print('MAE: ', mae)\n",
    "    print('RMSE: ', rmse)\n",
    "    \n",
    "    print('MAPE:',mape)\n",
    "    print('')\n",
    "    print('')\n",
    "    \n",
    "    return compare\n",
    "residuals_naive=naive_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_only=['Occupancy','Holiday name',\n",
    " 'Leadtime',\n",
    " 'Booking day of week',\n",
    " 'Day of week visit',\n",
    " 'Booking month',\n",
    " 'Month visit',\n",
    " 'Booking day date',\n",
    " 'Day visit date','Lagged Cancellation Amount',\n",
    " 'Lagged cancellation insurance Amount',\n",
    " 'Lagged travel insurance Amount',\n",
    " 'Physical capacity village level',\n",
    " 'Physical capacity village level for hotel',\n",
    " 'Physical capacity village level for comfort',\n",
    " 'Physical capacity village level for premium',\n",
    " 'Physical capacity village level for VIP',\n",
    " 'Rented villa nights before booking date on village level',\n",
    " 'Rented villa nights before booking date on village level for hotel',\n",
    " 'Rented villa nights before booking date on village level for comfort',\n",
    " 'Rented villa nights before booking date on village level for premium',\n",
    " 'Rented villa nights before booking date on village level for VIP',\n",
    " 'Cottage rent per person']\n",
    "scale_cols2 = [\n",
    "        'Physical capacity village level',\n",
    "        'Physical capacity village level for hotel', 'Physical capacity village level for comfort',\n",
    "        'Physical capacity village level for premium', 'Physical capacity village level for VIP', \n",
    "        'Rented villa nights before booking date on village level',\n",
    "        'Rented villa nights before booking date on village level for hotel',\n",
    "        'Rented villa nights before booking date on village level for comfort',\n",
    "        'Rented villa nights before booking date on village level for premium',\n",
    "        'Rented villa nights before booking date on village level for VIP',\n",
    "        'Cottage rent per person', 'Lagged Cancellation Amount','Lagged cancellation insurance Amount','Lagged travel insurance Amount'\n",
    "        \n",
    "    ]\n",
    "capacity_14 = horizon14[capacity_only].copy()\n",
    "capacity_7 = horizon7[capacity_only].copy()\n",
    "capacity_5 = horizon5[capacity_only].copy()\n",
    "capacity_1 = horizon1[capacity_only].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using two standard deviations for extreme prediction errors\n",
    "double_standard=2*capacity_14['Occupancy'].std()\n",
    "double_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment 1\n",
    "#no weather features model\n",
    "def no_weather_model(split_date='2023-10-01', shapE=False,residual=False):\n",
    "    \n",
    "   \n",
    "\n",
    "    frames= [capacity_14,capacity_7,capacity_5,capacity_1]\n",
    "    compare = pd.DataFrame(columns=['true','predicted','Leadtime','Model','difference','negative','Date visit','extreme'])\n",
    "    #model list\n",
    "    models = ['XGBRegressor', 'ridge regression', 'SVR']\n",
    "    #Setting the optimal parameters for each model and lead time\n",
    "    optimal_params = {\n",
    "        'XGBRegressor': {\n",
    "            14: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}, \n",
    "            7: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200},   \n",
    "            5: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200},  \n",
    "            1: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}    \n",
    "        },\n",
    "        'ridge regression': {\n",
    "            14: {'alpha': 5},  \n",
    "            7: {'alpha': 5},  \n",
    "            5: {'alpha': 5},   \n",
    "            1: {'alpha': 5}    \n",
    "        },\n",
    "        'SVR': {\n",
    "            14: {'C': 0.1, 'epsilon': 0.1, 'kernel': 'rbf'},  # Best Validation MAPE: 0.058\n",
    "            7: {'C': 0.1, 'epsilon': 0.01, 'kernel': 'rbf'},  # Best Validation MAPE: 0.023\n",
    "            5: {'C': 0.1, 'epsilon': 0.01, 'kernel': 'rbf'},  # Best Validation MAPE: 0.018\n",
    "            1: {'C': 10, 'epsilon': 0.01, 'kernel': 'rbf'}    # Best Validation MAPE: 0.006\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "    naive_maape=[0.123]\n",
    "    naive=[0.094]\n",
    "    naive_rmse=[0.126]\n",
    "    \n",
    "    masecompare = pd.DataFrame(columns=['Leadtime', 'Model','MAE','MAPE','RMSE','Approach'])\n",
    "\n",
    "    for model in models:\n",
    "        \n",
    "        for t in frames:\n",
    "            lead=t['Leadtime'].max()\n",
    "            # Perform the time-based split\n",
    "            # Prepare training data\n",
    "            split_date3 = '2022-09-30'\n",
    "            train = t.loc[:split_date3]\n",
    "            y_train = train['Occupancy']\n",
    "            X_train = train.drop(columns=['Occupancy'])\n",
    "            test = t.loc[split_date:]  \n",
    "            print(train.shape)\n",
    "            # Prepare the test data\n",
    "            X_test = test.drop(columns=['Occupancy'])\n",
    "            y_test = test['Occupancy']\n",
    "            if model == 'XGBRegressor':\n",
    "                model_instance = xgb.XGBRegressor(**optimal_params[model][lead], enable_categorical=True)\n",
    "            elif model == 'ridge regression':\n",
    "                model_instance = Ridge(**optimal_params[model][lead])\n",
    "            elif model == 'SVR':\n",
    "                model_instance = SVR(**optimal_params[model][lead])\n",
    "            model_instance.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model_instance.predict(X_test)\n",
    "           \n",
    "            compare = comparison(y_test, y_pred, lead,compare,model,X_test,double_standard)\n",
    "            \n",
    "\n",
    "            mae = np.round(mean_absolute_error(y_test, y_pred), 3)\n",
    "            rmse = np.round(root_mean_squared_error(y_test, y_pred), 3)\n",
    "            \n",
    "            mape=np.round(mean_absolute_percentage_error(y_test, y_pred), 3)\n",
    "            print(model)\n",
    "            print('Test leadtime',lead)\n",
    "            print(f\"MAE for {model}: {mae}\")\n",
    "            print(f\"RMSE for {model}: {rmse}\")\n",
    "            print(f\"MAPE for {model}: {mape}\")\n",
    "           \n",
    "            \n",
    "            new_row = pd.DataFrame([{'Leadtime': lead, 'Model': model,'MAE':mae,'RMSE':rmse,'MAPE':mape,'Approach':'No_weather'}])\n",
    "\n",
    "# Concatenate the new row with the existing DataFrame\n",
    "            masecompare = pd.concat([masecompare, new_row], ignore_index=True)\n",
    "            \n",
    "\n",
    "            # Measuring feature importance\n",
    "            if shapE:\n",
    "                if isinstance(model_instance, xgb.XGBRegressor):\n",
    "                    explainer = shap.TreeExplainer(model_instance)\n",
    "                    shap_values = explainer.shap_values(X_test)\n",
    "                elif isinstance(model_instance, SVR):\n",
    "                    continue  # Skip SHAP for SVR\n",
    "                else:\n",
    "                    explainer = shap.LinearExplainer(model_instance, X_train)\n",
    "                    shap_values = explainer.shap_values(X_test)\n",
    "                    \n",
    "                plt.figure()\n",
    "                shap.summary_plot(shap_values, X_test, show=False)\n",
    "                plt.title(f\"SHAP Leadtime for {model} (MAPE: {mape})\")\n",
    "                plt.show()\n",
    "            \n",
    "            # Print comparison of results\n",
    "       \n",
    "            if residual:\n",
    "                # Stationarity of errors\n",
    "                time_series = compare['difference'].copy()\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(time_series, label=f\"Errors forecast horizon {lead} for {model} (MAE: {mae})\")\n",
    "                \n",
    "                # Rolling mean and variance\n",
    "                rolling_mean = time_series.rolling(window=lead).mean()\n",
    "                rolling_std = time_series.rolling(window=lead).std()\n",
    "\n",
    "                # Plot rolling statistics\n",
    "                plt.plot(rolling_mean, color='red', label='Rolling Mean')\n",
    "                plt.plot(rolling_std, color='black', label='Rolling Std')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "    \n",
    "# Plot MAAPE comparison across different lead times and models\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name in masecompare['Model'].unique():\n",
    "        subset = masecompare[masecompare['Model'] == model_name]\n",
    "        plt.plot(subset['Leadtime'], subset['MAPE'], label=model_name, marker='o')\n",
    "        \n",
    "    plt.axhline( naive, label='Naive Baseline', marker='x', linestyle='--', color='black')     \n",
    "    plt.title('MAPE Comparison Across Lead Times and Models')\n",
    "    plt.xlabel('Leadtime')\n",
    "    plt.ylabel('MAPE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # Plot MAE comparison across different lead times and models\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name in masecompare['Model'].unique():\n",
    "        subset = masecompare[masecompare['Model'] == model_name]\n",
    "        plt.plot(subset['Leadtime'], subset['MAE'], label=model_name, marker='o')\n",
    "        \n",
    "    plt.axhline( naive, label='Naive Baseline', marker='x', linestyle='--', color='black')     \n",
    "    plt.title('MAE Comparison Across Lead Times and Models')\n",
    "    plt.xlabel('Leadtime')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return masecompare,compare\n",
    "no_weather,residuals_no_weather=no_weather_model(shapE=True,residual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning for experiment 1 no weather features\n",
    "def tuning_noweather( split_date='2023-10-01'):\n",
    "\n",
    "    # Initialize the models\n",
    "    models = [xgb.XGBRegressor(enable_categorical=True),\n",
    "              Ridge(),\n",
    "              SVR()]\n",
    "    \n",
    "    # Prepare training data\n",
    "    \n",
    "    frames = [capacity_16,capacity_7,capacity_5,capacity_1]\n",
    "   \n",
    "    \n",
    "    for model in models:\n",
    "        for frame in frames:\n",
    "            lead=frame['Leadtime'].max()\n",
    "            train,test,validation=train_test_validation(df=frame)\n",
    "            y_train = train['Occupancy']\n",
    "            X_train = train.drop(columns=['Occupancy'])\n",
    "            \n",
    "            y_val = validation['Occupancy']\n",
    "            X_val = validation.drop(columns=['Occupancy'])\n",
    "\n",
    "            if isinstance(model, xgb.XGBRegressor):\n",
    "                param_grid = {\n",
    "                    'n_estimators': [100,200,500],\n",
    "                    'max_depth': [3, 5, 7, 14],\n",
    "                    'learning_rate': [0.001, 0.01, 0.1]\n",
    "                }\n",
    "            elif isinstance(model, SVR):\n",
    "                param_grid = {'C': [0.1, 1, 10], 'epsilon': [0.01, 0.1, 0.2],'kernel':['rbf']}\n",
    "            else:\n",
    "                param_grid = {'alpha': [0, 0.1, 1, 3, 5]}\n",
    "        \n",
    "        # Set up TimeSeriesSplit for cross-validation\n",
    "            tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "            # Initialize GridSearchCV with TimeSeriesSplit\n",
    "            grid_search = GridSearchCV(estimator=model, \n",
    "                                    param_grid=param_grid,\n",
    "                                    scoring='neg_mean_absolute_percentage_error',  #MAAPE for scoring\n",
    "                                    cv=tscv,\n",
    "                                    n_jobs=-1)\n",
    "            \n",
    "            # Fit the grid search model\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            # Get the best parameters and best score\n",
    "            best_params = grid_search.best_params_\n",
    "              \n",
    "            # Initialize the model with the best parameters\n",
    "            best_model = model.set_params(**best_params).fit(X_train, y_train)\n",
    "\n",
    "            # Fit the best model \n",
    "            y_val_pred = best_model.predict(X_val)\n",
    "            mape=np.round(mean_absolute_percentage_error(y_val, y_val_pred), 3)\n",
    "            \n",
    "            print(f\"Best Parameters for Leadtime {lead} for {model.__class__.__name__}:\", best_params)\n",
    "            print(\"Best Validation MAPE Score:\", mape)\n",
    "\n",
    "tuning_noweather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment 2\n",
    "#unscaled model\n",
    "def unscaled_model(split_date='2023-10-01', shapE=False,residual=False):\n",
    "  \n",
    "   \n",
    "\n",
    "    \n",
    "    compare = pd.DataFrame(columns=['true','predicted','Leadtime','Model','difference','negative','Date visit','extreme'])\n",
    "    #model list\n",
    "    models = ['XGBRegressor', 'ridge regression', 'SVR']\n",
    "    # Setting the optimal parameters for each model and lead time\n",
    "    optimal_params = {\n",
    "        'XGBRegressor': {\n",
    "            1: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100},\n",
    "            5: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200},\n",
    "            7: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500},\n",
    "            14: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200},\n",
    "        },\n",
    "        'Ridge': {\n",
    "            1: {'alpha': 0.1},\n",
    "            5: {'alpha': 1},\n",
    "            7: {'alpha': 0},\n",
    "            14: {'alpha': 0.1},\n",
    "        },\n",
    "        'SVR': {\n",
    "            1: {'C': 10, 'epsilon': 0.01, 'kernel': 'rbf'},\n",
    "            5: {'C': 0.1, 'epsilon': 0.01, 'kernel': 'rbf'},\n",
    "            7: {'C': 0.1, 'epsilon': 0.01, 'kernel': 'rbf'},\n",
    "            14: {'C': 0.1, 'epsilon': 0.1, 'kernel': 'rbf'},\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "    naive_maape=[0.123]\n",
    "    naive=[0.094]\n",
    "    naive_rmse=[0.126]\n",
    "    \n",
    "    masecompare = pd.DataFrame(columns=['Leadtime', 'Model','MAE','MAPE','RMSE','Approach'])\n",
    "\n",
    "    for model in models:\n",
    "        \n",
    "        for t in frames:\n",
    "            lead=t['Leadtime'].max()\n",
    "            # Perform the time-based split\n",
    "            # Prepare training data\n",
    "            split_date3 = '2022-09-30'\n",
    "            train = t.loc[:split_date3]\n",
    "            y_train = train['Occupancy']\n",
    "            X_train = train.drop(columns=['Occupancy'])\n",
    "            test = t.loc[split_date:]  \n",
    "            print(train.shape)\n",
    "            # Prepare the test data\n",
    "            X_test = test.drop(columns=['Occupancy'])\n",
    "            y_test = test['Occupancy']\n",
    "            if model == 'XGBRegressor':\n",
    "                model_instance = xgb.XGBRegressor(**optimal_params[model][lead], enable_categorical=True)\n",
    "            elif model == 'Ridge':\n",
    "                model_instance = Ridge(**optimal_params[model][lead])\n",
    "            elif model == 'SVR':\n",
    "                model_instance = SVR(**optimal_params[model][lead])\n",
    "            model_instance.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model_instance.predict(X_test)\n",
    "           \n",
    "            compare = comparison(y_test, y_pred, lead,compare,model,X_test,double_standard)\n",
    "            \n",
    "\n",
    "            mae = np.round(mean_absolute_error(y_test, y_pred), 3)\n",
    "            rmse = np.round(root_mean_squared_error(y_test, y_pred), 3)\n",
    "            #maape_score=np.round(maape(y_test, y_pred), 3)\n",
    "            mape=np.round(mean_absolute_percentage_error(y_test, y_pred), 3)\n",
    "            print(model)\n",
    "            print('Test leadtime',lead)\n",
    "            print(f\"MAE for {model}: {mae}\")\n",
    "            print(f\"RMSE for {model}: {rmse}\")\n",
    "            print(f\"MAPE for {model}: {mape}\")\n",
    "           \n",
    "            \n",
    "            new_row = pd.DataFrame([{'Leadtime': lead, 'Model': model,'MAE':mae,'RMSE':rmse,'MAPE':mape,'Approach':'Unscaled'}])\n",
    "\n",
    "# Concatenate the new row with the existing DataFrame\n",
    "            masecompare = pd.concat([masecompare, new_row], ignore_index=True)\n",
    "            \n",
    "\n",
    "            # Measuring feature importance\n",
    "            if shapE:\n",
    "                if isinstance(model_instance, xgb.XGBRegressor):\n",
    "                    explainer = shap.TreeExplainer(model_instance)\n",
    "                    shap_values = explainer.shap_values(X_test)\n",
    "                elif isinstance(model_instance, SVR):\n",
    "                    continue  # Skip SHAP for SVR\n",
    "                else:\n",
    "                    explainer = shap.LinearExplainer(model_instance, X_train)\n",
    "                    shap_values = explainer.shap_values(X_test)\n",
    "                    \n",
    "                plt.figure()\n",
    "                shap.summary_plot(shap_values, X_test, show=False)\n",
    "                plt.title(f\"SHAP Leadtime for {model} (MAPE: {mape})\")\n",
    "                plt.show()\n",
    "            \n",
    "            # Print comparison of results\n",
    "       \n",
    "            if residual:\n",
    "                # Stationarity of errors\n",
    "                time_series = compare['difference'].copy()\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(time_series, label=f\"Errors forecast horizon {lead} for {model} (MAE: {mae}))\")\n",
    "                \n",
    "                # Rolling mean and variance\n",
    "                rolling_mean = time_series.rolling(window=lead).mean()\n",
    "                rolling_std = time_series.rolling(window=lead).std()\n",
    "\n",
    "                # Plot rolling statistics\n",
    "                plt.plot(rolling_mean, color='red', label='Rolling Mean')\n",
    "                plt.plot(rolling_std, color='black', label='Rolling Std')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "    \n",
    "# Plot MAAPE comparison across different lead times and models\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name in masecompare['Model'].unique():\n",
    "        subset = masecompare[masecompare['Model'] == model_name]\n",
    "        plt.plot(subset['Leadtime'], subset['MAPE'], label=model_name, marker='o')\n",
    "        \n",
    "    plt.axhline( naive, label='Naive Baseline', marker='x', linestyle='--', color='black')     \n",
    "    plt.title('MAPE Comparison Across Lead Times and Models')\n",
    "    plt.xlabel('Leadtime')\n",
    "    plt.ylabel('MAPE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # Plot MAE comparison across different lead times and models\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name in masecompare['Model'].unique():\n",
    "        subset = masecompare[masecompare['Model'] == model_name]\n",
    "        plt.plot(subset['Leadtime'], subset['MAE'], label=model_name, marker='o')\n",
    "        \n",
    "    plt.axhline( naive, label='Naive Baseline', marker='x', linestyle='--', color='black')     \n",
    "    plt.title('MAE Comparison Across Lead Times and Models')\n",
    "    plt.xlabel('Leadtime')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return masecompare,compare\n",
    "unscaled,residuals_unscaled=unscaled_model(shapE=True,residual=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning for experiment 2 unscaled\n",
    "def tuning_unscaled( split_date='2023-10-01'):\n",
    "\n",
    "    # Initialize the models\n",
    "    models = [xgb.XGBRegressor(enable_categorical=True),\n",
    "              Ridge(),\n",
    "              SVR()]\n",
    "    \n",
    "    # Prepare training data\n",
    "    \n",
    "    frames = [lead16,lead7,lead5,lead1]\n",
    "   \n",
    "    \n",
    "    for model in models:\n",
    "        for frame in frames:\n",
    "            lead=frame['Leadtime'].max()\n",
    "            train,test,validation=train_test_validation(df=frame)\n",
    "            y_train = train['Occupancy']\n",
    "            X_train = train.drop(columns=['Occupancy'])\n",
    "            \n",
    "            y_val = validation['Occupancy']\n",
    "            X_val = validation.drop(columns=['Occupancy'])\n",
    "\n",
    "            if isinstance(model, xgb.XGBRegressor):\n",
    "                param_grid = {\n",
    "                    'n_estimators': [100,200,500],\n",
    "                    'max_depth': [3, 5, 7, 14],\n",
    "                    'learning_rate': [0.001, 0.01, 0.1]\n",
    "                }\n",
    "            elif isinstance(model, SVR):\n",
    "                param_grid = {'C': [0.1, 1, 10], 'epsilon': [0.01, 0.1, 0.2],'kernel':['rbf']}\n",
    "            else:\n",
    "                param_grid = {'alpha': [0, 0.1, 1, 3, 5]}\n",
    "        \n",
    "        # Set up TimeSeriesSplit for cross-validation\n",
    "            tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "            # Initialize GridSearchCV with TimeSeriesSplit\n",
    "            grid_search = GridSearchCV(estimator=model, \n",
    "                                    param_grid=param_grid,\n",
    "                                    scoring='neg_mean_absolute_percentage_error',  #MAAPE for scoring\n",
    "                                    cv=tscv,\n",
    "                                    n_jobs=-1)\n",
    "            \n",
    "            # Fit the grid search model\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            # Get the best parameters and best score\n",
    "            best_params = grid_search.best_params_\n",
    "              \n",
    "            # Initialize the model with the best parameters\n",
    "            best_model = model.set_params(**best_params).fit(X_train, y_train)\n",
    "\n",
    "            # Fit the best model \n",
    "            y_val_pred = best_model.predict(X_val)\n",
    "            mape=np.round(mean_absolute_percentage_error(y_val, y_val_pred), 3)\n",
    "            \n",
    "            print(f\"Best Parameters for Leadtime {lead} for {model.__class__.__name__}:\", best_params)\n",
    "            print(\"Best Validation MAPE Score:\", mape)\n",
    "\n",
    "tuning_unscaled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing models from experiment 1\n",
    "\n",
    "def plot_best_model_approach(df1, df2,xp1=False,xp2=False,xp3=False):\n",
    "    # Add an Approach column to distinguish between general and specific\n",
    "    if xp1==True:\n",
    "        df1['Approach'] = 'No_weather'\n",
    "        df2['Approach'] = 'Unscaled'\n",
    "\n",
    "    if xp2==True:\n",
    "        df1['Approach'] = 'Scaled'\n",
    "        df2['Approach'] = 'Unscaled'\n",
    "\n",
    "    if xp3==True:\n",
    "        df1['Approach'] = 'Blended'\n",
    "        df2['Approach'] = 'Separate'\n",
    "  \n",
    "\n",
    "\n",
    "    # Concatenate the two DataFrames\n",
    "    combined_df = pd.concat([df1,df2])\n",
    "    leads = np.unique(combined_df['Leadtime'])\n",
    "    \n",
    "    # Prepare highlights DataFrames for each metric\n",
    "    highlights_mae = pd.DataFrame(columns=combined_df.columns)\n",
    "    highlights_MAPE = pd.DataFrame(columns=combined_df.columns)\n",
    "    highlights_RMSE = pd.DataFrame(columns=combined_df.columns)\n",
    "    # Identify best values for each metric\n",
    "    for lead in leads:\n",
    "        temp_df = combined_df[combined_df['Leadtime'] == lead]\n",
    "        highlights_mae = pd.concat([highlights_mae, temp_df.sort_values(by='MAE').drop_duplicates(['Model'])], ignore_index=True)\n",
    "        highlights_MAPE = pd.concat([highlights_MAPE, temp_df.sort_values(by='MAPE').drop_duplicates(['Model'])], ignore_index=True)\n",
    "        highlights_RMSE = pd.concat([highlights_RMSE, temp_df.sort_values(by='RMSE').drop_duplicates(['Model'])], ignore_index=True)\n",
    "    # Plot configurations\n",
    "    if xp1:\n",
    "        markers = {'No_weather': 's', 'Unscaled': 'o'}\n",
    "    elif xp2:\n",
    "        markers = {'Scaled': 's', 'Unscaled': 'o'}\n",
    "    elif xp3:\n",
    "        markers = {'Blended': 's', 'Separate': 'o'}\n",
    "    colors = {'XGBRegressor': 'blue', 'ridge regression': 'green', 'SVR': 'red'}\n",
    "\n",
    "    def plot_metric(metric, highlights_df, ylabel, baseline_key):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for model in highlights_df['Model'].unique():\n",
    "            model_data = highlights_df[highlights_df['Model'] == model]\n",
    "            for approach in model_data['Approach'].unique():\n",
    "                approach_data = model_data[model_data['Approach'] == approach]\n",
    "                plt.scatter(\n",
    "                    approach_data['Leadtime'], \n",
    "                    approach_data[metric], \n",
    "                    marker=markers[approach], \n",
    "                    color=colors[model], \n",
    "                    label=f'{model} ({approach})',\n",
    "                    s=100\n",
    "                )\n",
    "\n",
    "        plt.title(f'Best Model Approaches for {metric} across forecast horizons')\n",
    "        plt.xlabel('Leadtime')\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "    # Plot the MAE and MAPE graphs\n",
    "    plot_metric('MAE', highlights_mae, 'MAE', 'MAE')\n",
    "    plot_metric('MAPE', highlights_MAPE, 'MAPE', 'MAPE')\n",
    "    plot_metric('RMSE', highlights_RMSE, 'RMSE', 'RMSE')\n",
    "\n",
    "    final_comparison=pd.concat([highlights_MAPE,highlights_mae,highlights_RMSE])\n",
    "    final_comparison = final_comparison.drop_duplicates()\n",
    "    final_comparison = final_comparison.dropna(axis=1)\n",
    "    return final_comparison\n",
    "# Use the function with your DataFrames\n",
    "best_unscaled=plot_best_model_approach(no_weather, unscaled,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment 2\n",
    "#Robust scaling\n",
    "\n",
    "def scale_model(split_date='2023-10-01', shapE=False,residual=False):\n",
    "\n",
    "    compare = pd.DataFrame(columns=['true','predicted','Leadtime','Model','difference','negative','Date visit','extreme'])\n",
    "    \n",
    "    \n",
    "    #model list\n",
    "    models = ['XGBRegressor', 'ridge regression', 'SVR']\n",
    "    # Define the optimal parameters for each model and lead time\n",
    "    optimal_params = {\n",
    "        'XGBRegressor': {\n",
    "            1: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100},\n",
    "            5: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200},\n",
    "            7: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500},\n",
    "            14: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
    "        },\n",
    "        'ridge regression': {\n",
    "            1: {'alpha': 3},\n",
    "            5: {'alpha': 5},\n",
    "            7: {'alpha': 5},\n",
    "            14: {'alpha': 5}\n",
    "        },\n",
    "        'SVR': {\n",
    "            1: {'C': 10, 'epsilon': 0.01, 'kernel': 'rbf'},\n",
    "            5: {'C': 1, 'epsilon': 0.01, 'kernel': 'rbf'},\n",
    "            7: {'C': 1, 'epsilon': 0.01, 'kernel': 'rbf'},\n",
    "            14: {'C': 0.1, 'epsilon': 0.01, 'kernel': 'rbf'}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \n",
    "    masecompare = pd.DataFrame(columns=['Leadtime', 'Model','MAE','RMSE','MAPE','Approach'])\n",
    "    scaler=RobustScaler()\n",
    "    for model in models:\n",
    "        \n",
    "        for t in frames:\n",
    "            lead=t['Leadtime'].max()\n",
    "            # Perform the time-based split\n",
    "            # Prepare training data\n",
    "            train = t.loc[:split_date]\n",
    "            y_train = train['Occupancy']\n",
    "            X_train = train.drop(columns=['Occupancy'])\n",
    "                #Scaling all non categorical features\n",
    "            X_train[scale_cols] = scaler.fit_transform(X_train[scale_cols])\n",
    "            \n",
    "            test = t.loc[split_date:]  \n",
    "            \n",
    "            # Prepare the test data\n",
    "            X_test = test.drop(columns=['Occupancy'])\n",
    "            X_test[scale_cols] = scaler.transform(X_test[scale_cols])\n",
    "            y_test = test['Occupancy']\n",
    "            if model == 'XGBRegressor':\n",
    "                model_instance = xgb.XGBRegressor(**optimal_params[model][lead], enable_categorical=True)\n",
    "     \n",
    "            elif model == 'ridge regression':\n",
    "                model_instance = Ridge(**optimal_params[model][lead])\n",
    "            elif model == 'SVR':\n",
    "                model_instance = SVR(**optimal_params[model][lead])\n",
    "            model_instance.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model_instance.predict(X_test)\n",
    "           \n",
    "            compare = comparison(y_test, y_pred, lead,compare,model,X_test,double_standard)\n",
    "            \n",
    "\n",
    "            mae = np.round(mean_absolute_error(y_test, y_pred), 3)\n",
    "            rmse=np.round(root_mean_squared_error(y_test, y_pred), 3)\n",
    "            #maape_score=np.round(maape(y_test, y_pred), 3)\n",
    "            mape=np.round(mean_absolute_percentage_error(y_test, y_pred), 3)\n",
    "            print(model)\n",
    "            print('Test leadtime',lead)\n",
    "            print(f\"MAE for {model}: {mae}\")\n",
    "            print(f\"RMSE for {model}: {rmse}\")\n",
    "            print(f\"MAPE for {model}: {mape}\")\n",
    "           \n",
    "            \n",
    "            new_row = pd.DataFrame([{'Leadtime': lead, 'Model': model,'MAE':mae,'MAPE':mape,'Approach':'Scaled','RMSE':rmse}])\n",
    "\n",
    "# Concatenate the new row with the existing DataFrame\n",
    "            masecompare = pd.concat([masecompare, new_row], ignore_index=True)\n",
    "            \n",
    "\n",
    "            # Measuring feature importance\n",
    "            if shapE:\n",
    "                if isinstance(model_instance, xgb.XGBRegressor):\n",
    "                    explainer = shap.TreeExplainer(model_instance)\n",
    "                    shap_values = explainer.shap_values(X_test)\n",
    "                elif isinstance(model_instance, SVR):\n",
    "                    continue  # Skip SHAP for SVR\n",
    "                else:\n",
    "                    explainer = shap.LinearExplainer(model_instance, X_train)\n",
    "                    shap_values = explainer.shap_values(X_test)\n",
    "                    \n",
    "                plt.figure()\n",
    "                shap.summary_plot(shap_values, X_test, show=False)\n",
    "                plt.title(f\"SHAP for {model} (MAPE: {mape})\")\n",
    "                plt.show()\n",
    "            \n",
    "            # Print comparison of results\n",
    "            \n",
    "            #print(compare.describe(include='all'))\n",
    "            if residual:\n",
    "                # Stationarity of errors\n",
    "                time_series = compare['difference'].copy()\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(time_series, label=f\"Errors forecast horizon {lead} for {model} (MAE: {mae})\")\n",
    "                \n",
    "                # Rolling mean and variance\n",
    "                rolling_mean = time_series.rolling(window=lead).mean()\n",
    "                rolling_std = time_series.rolling(window=lead).std()\n",
    "\n",
    "                # Plot rolling statistics\n",
    "                plt.plot(rolling_mean, color='red', label='Rolling Mean')\n",
    "                plt.plot(rolling_std, color='black', label='Rolling Std')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "    \n",
    "# Plot MAAPE comparison across different lead times and models\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name in masecompare['Model'].unique():\n",
    "        subset = masecompare[masecompare['Model'] == model_name]\n",
    "        plt.plot(subset['Leadtime'], subset['MAPE'], label=model_name, marker='o')\n",
    "        \n",
    "    \n",
    "    plt.title('MAPE Comparison Across Lead Times and Models')\n",
    "    plt.xlabel('Leadtime')\n",
    "    plt.ylabel('MAPE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # Plot MAE comparison across different lead times and models\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name in masecompare['Model'].unique():\n",
    "        subset = masecompare[masecompare['Model'] == model_name]\n",
    "        plt.plot(subset['Leadtime'], subset['MAE'], label=model_name, marker='o')\n",
    "        \n",
    "      \n",
    "    plt.title('MAE Comparison Across Lead Times and Models')\n",
    "    plt.xlabel('Leadtime')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return masecompare,compare\n",
    "scaled_model,residuals_scale=scale_model(shapE=True,residual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning for experiment 2\n",
    "#Tuning with robust scaling\n",
    "\n",
    "def tuning_scaling( split_date='2023-10-01'):\n",
    "\n",
    "    # Initialize the models\n",
    "    models = [SVR(),xgb.XGBRegressor(enable_categorical=True),\n",
    "              Ridge()]\n",
    "    \n",
    "\n",
    "    \n",
    "    for model in models:\n",
    "        for frame in frames:\n",
    "           \n",
    "            train,test,validation=train_test_validation(df=frame)\n",
    "            scaler=RobustScaler()\n",
    "            \n",
    "            y_train = train['Occupancy']\n",
    "            X_train = train.drop(columns=['Occupancy'])\n",
    "\n",
    "            y_val=validation['Occupancy']\n",
    "            X_val=validation.drop(columns=['Occupancy'])\n",
    "\n",
    "            #Scaling all non categorical features\n",
    "            X_train[scale_cols] = scaler.fit_transform(X_train[scale_cols])\n",
    "            X_val[scale_cols] = scaler.transform(X_val[scale_cols])\n",
    "            if isinstance(model, xgb.XGBRegressor):\n",
    "                \n",
    "                param_grid = {\n",
    "                    'n_estimators': [100,200,500],\n",
    "                    'max_depth': [3, 5, 7, 14],\n",
    "                    'learning_rate': [0.001, 0.01, 0.1]\n",
    "                }\n",
    "\n",
    "              \n",
    "\n",
    "            elif isinstance(model, SVR):\n",
    "                param_grid = {'C': [0.1, 1, 10], 'epsilon': [0.01, 0.1, 0.2],'kernel':['rbf']}\n",
    "            else:\n",
    "                param_grid = {'alpha': [0, 0.1, 1, 3, 5]}\n",
    "        \n",
    "        # Set up TimeSeriesSplit for cross-validation\n",
    "            tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "            # Initialize GridSearchCV with TimeSeriesSplit\n",
    "            grid_search = GridSearchCV(estimator=model, \n",
    "                                    param_grid=param_grid,\n",
    "                                    scoring='neg_mean_absolute_percentage_error',  #MAAPE for scoring\n",
    "                                    cv=tscv,\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "            # Fit the grid search model\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_params = grid_search.best_params_\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_model = model.set_params(**best_params).fit(X_train, y_train)\n",
    "# Predict on the validation set using the best model\n",
    "            y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "            # Get the best parameters and best score\n",
    "            \n",
    "            mape=np.round(mean_absolute_percentage_error(y_val, y_val_pred), 3)\n",
    "            print('Leadtime:',frame['Leadtime'].max())\n",
    "            print(f\"Best Parameters for {model.__class__.__name__}:\", best_params)\n",
    "            print(\"Best Validation MAPE Score:\", mape)\n",
    "    \n",
    "tuning_scaling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing scaling with unscaled best models\n",
    "print('Scaled models')\n",
    "print(scaled_model)\n",
    "print('Unscaled best')\n",
    "print(best_unscaled.sort_values(by='Model'))\n",
    "plot_best_model_approach(scaled_model,best_unscaled ,xp2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment 3\n",
    "#different model for different leads, different pca for weather and capacity\n",
    "def separate_pca(split_date='2023-10-01', shapE=False, residual=False):\n",
    "    # Define the test DataFrames based on lead times\n",
    "    \n",
    "    compare = pd.DataFrame(columns=['true','predicted','Leadtime','Model','difference','negative','Date visit','extreme'])\n",
    "    w_components=2\n",
    "    c_components=2\n",
    "    scaler=RobustScaler()\n",
    "\n",
    "\n",
    "   \n",
    "    # model list\n",
    "    models = ['XGBRegressor', 'ridge regression', 'SVR']\n",
    "    # Define the optimal parameters for each model and lead time\n",
    "    optimal_params = {\n",
    "        'XGBRegressor': {\n",
    "            14: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500},\n",
    "            7: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500},\n",
    "            5: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500},\n",
    "            1: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}\n",
    "        },\n",
    "        'ridge regression': {\n",
    "            14: {'alpha': 5},\n",
    "            7: {'alpha': 5},\n",
    "            5: {'alpha': 5},\n",
    "            1: {'alpha': 5}\n",
    "        },\n",
    "        'SVR': {\n",
    "            14: {'C': 0.1, 'epsilon': 0.1, 'kernel': 'rbf'},\n",
    "            7: {'C': 1, 'epsilon': 0.2, 'kernel': 'rbf'},\n",
    "            5: {'C': 1, 'epsilon': 0.2, 'kernel': 'rbf'},\n",
    "            1: {'C': 1, 'epsilon': 0.01, 'kernel': 'rbf'}\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    \n",
    "    masecompare = pd.DataFrame(columns=['Leadtime', 'Model','MAE','MAPE','RMSE','Approach'])\n",
    "\n",
    "    for model in models:\n",
    "        \n",
    "        for t in frames:\n",
    "            lead=t['Leadtime'].max()\n",
    "            # Perform the time-based split\n",
    "            # Prepare training data\n",
    "            split_date3 = '2022-09-30'\n",
    "            train = t.loc[:split_date3]\n",
    "            y_train = train['Occupancy']\n",
    "            X_train = train.drop(columns=['Occupancy'])\n",
    "            test = t.loc[split_date:]  \n",
    "\n",
    "            # Prepare the test data\n",
    "            X_test = test.drop(columns=['Occupancy'])\n",
    "            y_test = test['Occupancy']\n",
    "            #Copy for comparison date index since PCA drops index\n",
    "            a=X_test.copy()\n",
    "\n",
    "                            #Scaling all non categorical features\n",
    "            X_train[scale_cols] = scaler.fit_transform(X_train[scale_cols])\n",
    "        \n",
    "            # Apply PCA for the training set\n",
    "            pca_weather = PCA(n_components=w_components)\n",
    "            pca_capacity = PCA(n_components=c_components)\n",
    "            \n",
    "            X_train_weather = pd.DataFrame(pca_weather.fit_transform(X_train[weather_cols]), columns=[f'PC_weather_{i+1}' for i in range(w_components)])\n",
    "            X_train_capacity = pd.DataFrame(pca_capacity.fit_transform(X_train[capacity_cols]), columns=[f'PC_capacity_{i+1}' for i in range(c_components)])\n",
    "            X_train = pd.concat([X_train_weather.reset_index(drop=True), X_train_capacity.reset_index(drop=True), train[cat_cols].reset_index(drop=True)], axis=1)\n",
    "\n",
    "                            #Scaling all non categorical features\n",
    "            X_test[scale_cols] = scaler.transform(X_test[scale_cols])\n",
    "        \n",
    "            # Apply PCA for the test set\n",
    "          \n",
    "            X_test_weather = pd.DataFrame(pca_weather.transform(X_test[weather_cols]), columns=[f'PC_weather_{i+1}' for i in range(w_components)])\n",
    "            X_test_capacity = pd.DataFrame(pca_capacity.transform(X_test[capacity_cols]), columns=[f'PC_capacity_{i+1}' for i in range(c_components)])\n",
    "            X_test = pd.concat([X_test_weather.reset_index(drop=True), X_test_capacity.reset_index(drop=True), test[cat_cols].reset_index(drop=True)], axis=1)\n",
    "            \n",
    "\n",
    "            if model == 'XGBRegressor':\n",
    "                model_instance = xgb.XGBRegressor(**optimal_params[model][lead], enable_categorical=True)\n",
    "            elif model == 'ridge regression':\n",
    "                model_instance = Ridge(**optimal_params[model][lead])\n",
    "            elif model == 'SVR':\n",
    "                model_instance = SVR(**optimal_params[model][lead])\n",
    "            model_instance.fit(X_train, y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model_instance.predict(X_test)\n",
    "           \n",
    "            compare = comparison(y_test, y_pred, lead,compare,model,a,double_standard)\n",
    "            \n",
    "\n",
    "            mae = np.round(mean_absolute_error(y_test, y_pred), 3)\n",
    "            mape=np.round(mean_absolute_percentage_error(y_test, y_pred), 3)\n",
    "            rmse=np.round(root_mean_squared_error(y_test, y_pred), 3)\n",
    "            print(model)\n",
    "            print('Test leadtime',lead)\n",
    "            print(f\"MAE for {model}: {mae}\")\n",
    "            print(f\"MAPE for {model}: {mape}\")\n",
    "           \n",
    "            \n",
    "            new_row = pd.DataFrame([{'Leadtime': lead, 'Model': model,'MAE':mae,'MAPE':mape,'RMSE':rmse,'Approach':'Separate'}])\n",
    "\n",
    "# Concatenate the new row with the existing DataFrame\n",
    "            masecompare = pd.concat([masecompare, new_row], ignore_index=True)\n",
    "            \n",
    "\n",
    "            # Measuring feature importance\n",
    "            if shapE:\n",
    "                if model=='XGBRegressor':\n",
    "                    explainer = shap.TreeExplainer(model_instance)\n",
    "                    shap_values = explainer.shap_values(X_test)\n",
    "                elif model=='SVR':\n",
    "                    continue  # Skip SHAP for SVR\n",
    "                else:\n",
    "                    explainer = shap.LinearExplainer(model_instance, X_train)\n",
    "                    shap_values = explainer.shap_values(X_test)\n",
    "                    \n",
    "                plt.figure()\n",
    "                shap.summary_plot(shap_values, X_test, show=False)\n",
    "                plt.title(f\"SHAP Leadtime {lead} for {model} (MAPE: {mape})\")\n",
    "                plt.show()\n",
    "            \n",
    "            # Print comparison of results\n",
    "           \n",
    "            #print(compare.describe(include='all'))\n",
    "            if residual:\n",
    "                # Stationarity of errors\n",
    "                time_series = compare['difference'].copy()\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(time_series, label=f\"Errors forecast horizon {lead} for {model} (MAE: {mae})\")\n",
    "                \n",
    "                # Rolling mean and variance\n",
    "                rolling_mean = time_series.rolling(window=lead).mean()\n",
    "                rolling_std = time_series.rolling(window=lead).std()\n",
    "\n",
    "                # Plot rolling statistics\n",
    "                plt.plot(rolling_mean, color='red', label='Rolling Mean')\n",
    "                plt.plot(rolling_std, color='black', label='Rolling Std')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "    \n",
    "# Plot MAPE comparison across different lead times and models\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name in masecompare['Model'].unique():\n",
    "        subset = masecompare[masecompare['Model'] == model_name]\n",
    "        plt.plot(subset['Leadtime'], subset['MAPE'], label=model_name, marker='o')\n",
    "        \n",
    "    #plt.plot(np.unique(masecompare['Leadtime']), naive_MAPE, label='Naive Baseline', marker='x', linestyle='--', color='black')   \n",
    "    plt.title('MAPE Comparison Across Lead Times and Models')\n",
    "    plt.xlabel('Leadtime')\n",
    "    plt.ylabel('MAPE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # Plot MAE comparison across different lead times and models\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name in masecompare['Model'].unique():\n",
    "        subset = masecompare[masecompare['Model'] == model_name]\n",
    "        plt.plot(subset['Leadtime'], subset['MAE'], label=model_name, marker='o')\n",
    "        \n",
    "    #plt.plot(np.unique(masecompare['Leadtime']), sorted(naive), label='Naive Baseline', marker='x', linestyle='--', color='black')   \n",
    "    plt.title('MAE Comparison Across Lead Times and Models')\n",
    "    plt.xlabel('Leadtime')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return masecompare,compare\n",
    "# Call the function\n",
    "separate,residuals_separate=separate_pca(shapE=True,residual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_separate(df, w_components=2,c_components=2):\n",
    "    # Define columns to scale\n",
    "    split_date='2023-10-01'\n",
    "\n",
    "   \n",
    "\n",
    "    # Initialize models\n",
    "    models = [ SVR(), Ridge(),xgb.XGBRegressor(enable_categorical=True)]\n",
    "    scaler = RobustScaler()\n",
    "    # Set up TimeSeriesSplit for cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    best_params = {model.__class__.__name__: {} for model in models}\n",
    "    for frame in frames:\n",
    "        train,test,validation=train_test_validation(df=frame)\n",
    "        y_train = train['Occupancy']\n",
    "        X_train = train.drop(columns=['Occupancy'])\n",
    "\n",
    "        y_val=validation['Occupancy']\n",
    "        X_val=validation.drop(columns=['Occupancy'])\n",
    "\n",
    "            #Scaling all non categorical features\n",
    "        X_train[scale_cols] = scaler.fit_transform(X_train[scale_cols])\n",
    "        X_val[scale_cols] = scaler.transform(X_val[scale_cols])\n",
    "\n",
    "        # Apply PCA for the training set\n",
    "        pca_weather = PCA(n_components=w_components)\n",
    "        pca_capacity = PCA(n_components=c_components)\n",
    "        X_train_weather = pd.DataFrame(pca_weather.fit_transform(X_train[weather_cols]), columns=[f'PC_weather_{i+1}' for i in range(w_components)])\n",
    "        X_train_capacity = pd.DataFrame(pca_capacity.fit_transform(X_train[capacity_cols]), columns=[f'PC_capacity_{i+1}' for i in range(c_components)])\n",
    "        X_train = pd.concat([X_train_weather.reset_index(drop=True), X_train_capacity.reset_index(drop=True), X_train[cat_cols].reset_index(drop=True)], axis=1)\n",
    "\n",
    "        # Apply PCA for the validation set \n",
    "        X_val_weather = pd.DataFrame(pca_weather.transform(X_val[weather_cols]), columns=[f'PC_weather_{i+1}' for i in range(w_components)])\n",
    "        X_val_capacity = pd.DataFrame(pca_capacity.transform(X_val[capacity_cols]), columns=[f'PC_capacity_{i+1}' for i in range(c_components)])\n",
    "        X_val = pd.concat([X_val_weather.reset_index(drop=True), X_val_capacity.reset_index(drop=True), X_val[cat_cols].reset_index(drop=True)], axis=1)\n",
    "\n",
    "        for model in models:\n",
    "            print(f\"\\nTuning Model: {model.__class__.__name__}\")\n",
    "            \n",
    "            # Parameter grid\n",
    "            if isinstance(model, xgb.XGBRegressor):\n",
    "                param_grid = {\n",
    "                    'n_estimators': [100, 200, 500],\n",
    "                    'max_depth': [3, 5, 7, 14],\n",
    "                    'learning_rate': [0.001, 0.01, 0.1]\n",
    "                }\n",
    "            elif isinstance(model, SVR):\n",
    "                param_grid = {\n",
    "                    'C': [0.1, 1, 10],\n",
    "                    'epsilon': [0.01, 0.1, 0.2],\n",
    "                    'kernel': ['rbf']\n",
    "                }\n",
    "            else:\n",
    "                param_grid = {'alpha': [0, 0.1, 1, 3,5]}\n",
    "\n",
    "            # Set up TimeSeriesSplit for cross-validation\n",
    "            tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "            # Initialize GridSearchCV with TimeSeriesSplit\n",
    "            grid_search = GridSearchCV(estimator=model, \n",
    "                                    param_grid=param_grid,\n",
    "                                    scoring='neg_mean_absolute_percentage_error',  #MAAPE for scoring\n",
    "                                    cv=tscv,\n",
    "                                    n_jobs=-1)\n",
    "            \n",
    "            # Fit the grid search model\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            # Get the best parameters and best score\n",
    "            best_params = grid_search.best_params_\n",
    "              \n",
    "            # Initialize the model with the best parameters\n",
    "            best_model = model.set_params(**best_params).fit(X_train, y_train)\n",
    "\n",
    "            # Fit the best model \n",
    "            y_val_pred = best_model.predict(X_val)\n",
    "            mape=np.round(mean_absolute_percentage_error(y_val, y_val_pred), 3)\n",
    "            \n",
    "            print(f\"Best Parameters for Leadtime {frame['Leadtime'].max()} for {model.__class__.__name__}:\", best_params)\n",
    "            print(\"Best Validation MAPE Score:\", mape)\n",
    "tuning_separate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment 3\n",
    "#different model for different leads, blended pca weather and capacity\n",
    "def blended_pca(split_date='2023-10-01', shapE=False, residual=False):\n",
    "\n",
    "    compare = pd.DataFrame(columns=['true','predicted','Leadtime','Model','difference','negative','Date visit','extreme'])\n",
    "\n",
    "# Define the optimal parameters for each model and lead time\n",
    "  \n",
    "    optimal_params = {\n",
    "        'XGBRegressor': {\n",
    "            1: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100},\n",
    "            5: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100},\n",
    "            7: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500},\n",
    "            14: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
    "        },\n",
    "        'ridge regression': {\n",
    "            1: {'alpha': 5},\n",
    "            5: {'alpha': 3},\n",
    "            7: {'alpha': 3},\n",
    "            14: {'alpha': 5}\n",
    "        },\n",
    "        'SVR': {\n",
    "            1: {'C': 1, 'epsilon': 0.1, 'kernel': 'rbf'},\n",
    "            5: {'C': 0.1, 'epsilon': 0.1, 'kernel': 'rbf'},\n",
    "            7: {'C': 0.1, 'epsilon': 0.1, 'kernel': 'rbf'},\n",
    "            14: {'C': 0.1, 'epsilon': 0.1, 'kernel': 'rbf'}\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # setting up a dataframe to store performance metrics\n",
    "    masecompare = pd.DataFrame(columns=['Leadtime', 'Model', 'MAE', 'MAPE',\"RMSE\",'Approach'])\n",
    "\n",
    "    # Iterate through the models and lead times\n",
    "    for model in ['XGBRegressor', 'ridge regression', 'SVR']:\n",
    "        for frame in frames:\n",
    "            lead_time = frame['Leadtime'].max()\n",
    "            lead=lead_time\n",
    "            # Assign model with optimal parameters for the given lead time\n",
    "            if model == 'XGBRegressor':\n",
    "                model_instance = xgb.XGBRegressor( **optimal_params[model][lead_time],enable_categorical=True)\n",
    "            elif model == 'ridge regression':\n",
    "                model_instance = Ridge(**optimal_params[model][lead_time])\n",
    "            elif model == 'SVR':\n",
    "                model_instance = SVR(**optimal_params[model][lead_time])\n",
    "           \n",
    "\n",
    "             \n",
    "            split_date3 = '2022-09-30'\n",
    "            train = frame.loc[:split_date3]\n",
    "            test = frame.loc[split_date:]  \n",
    "            y_train = train['Occupancy']\n",
    "            X_train = train.drop(columns=['Occupancy'])\n",
    "            # Prepare the test data\n",
    "            X_test = test.drop(columns=['Occupancy'])\n",
    "            a=X_test.copy()\n",
    "            y_test = test['Occupancy']\n",
    "                # Scale data separately for train and test sets\n",
    "            scaler = RobustScaler()\n",
    "            X_train[scale_cols] = scaler.fit_transform(X_train[scale_cols])\n",
    "            X_test[scale_cols] = scaler.transform(test[scale_cols])\n",
    "\n",
    "         #Apply pca to train and test\n",
    "            pca_total = PCA(n_components=2)\n",
    "            X_train_pca = pd.DataFrame(pca_total.fit_transform(X_train[scale_cols]), columns=[f'PC_{i+1}' for i in range(2)])\n",
    "            X_train = pd.concat([X_train_pca.reset_index(drop=True), X_train[cat_cols].reset_index(drop=True)], axis=1)\n",
    "            \n",
    "            X_test_pca=pd.DataFrame(pca_total.transform(X_test[scale_cols]), columns=[f'PC_{i+1}' for i in range(2)])\n",
    "            X_test = pd.concat([X_test_pca.reset_index(drop=True), X_test[cat_cols].reset_index(drop=True)], axis=1)\n",
    "    \n",
    "            # Train the model\n",
    "            model_instance.fit(X_train, y_train)\n",
    "\n",
    "            # Predict on the test set\n",
    "            y_pred = model_instance.predict(X_test)\n",
    "\n",
    "            # Evaluate metrics\n",
    "            mae = np.round(mean_absolute_error(y_test, y_pred), 3)\n",
    "            rmse= np.round(root_mean_squared_error(y_test, y_pred), 3)\n",
    "            mape = np.round(mean_absolute_percentage_error(y_test, y_pred), 3)\n",
    "\n",
    "            # Store results\n",
    "            new_row = pd.DataFrame([{'Leadtime': lead_time, 'Model': model, 'MAE': mae, 'MAPE': mape,'RMSE':rmse,'Approach':'Blended'}])\n",
    "            masecompare = pd.concat([masecompare, new_row], ignore_index=True)\n",
    "            compare = comparison(y_test, y_pred, lead_time,compare,model,a,double_standard)\n",
    "            # Print evaluation results\n",
    "            print(f\"Lead time: {lead_time}, Model: {model}\")\n",
    "            print(f\"MAE: {mae}, MAPE: {mape}\")\n",
    "            if shapE==True:\n",
    "          \n",
    "                if isinstance(model_instance, xgb.XGBRegressor):\n",
    "                    explainer = shap.TreeExplainer(model_instance)\n",
    "                    shap_values = explainer.shap_values(X_test)\n",
    "                elif isinstance(model_instance, SVR):\n",
    "                    continue  # Skip SHAP for SVR\n",
    "             \n",
    "                elif isinstance(model_instance, Ridge):\n",
    "                    explainer = shap.LinearExplainer(model_instance, X_train)\n",
    "                    shap_values = explainer.shap_values(X_test)\n",
    "      \n",
    "                    \n",
    "                plt.figure(figsize=(10, 6))\n",
    "                shap.summary_plot(shap_values, X_test, show=False)\n",
    "                plt.title(f\"SHAP Leadtime {lead_time} for {model} (MAPE: {mape})\")\n",
    "                plt.show()\n",
    "            if residual:\n",
    "                # Stationarity of errors\n",
    "                time_series = compare['difference'].copy()\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(time_series, label=f\"Errors forecast horizon {lead} for {model} (MAE: {mae})\")\n",
    "                \n",
    "                # Rolling mean and variance\n",
    "                rolling_mean = time_series.rolling(window=lead).mean()\n",
    "                rolling_std = time_series.rolling(window=lead).std()\n",
    "\n",
    "                # Plot rolling statistics\n",
    "                plt.plot(rolling_mean, color='red', label='Rolling Mean')\n",
    "                plt.plot(rolling_std, color='black', label='Rolling Std')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "        print(\"\")\n",
    "    # Plot comparison of MAAPE across different lead times and models\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name in masecompare['Model'].unique():\n",
    "        subset = masecompare[masecompare['Model'] == model_name]\n",
    "        plt.plot(subset['Leadtime'], subset['MAPE'], label=model_name, marker='o')\n",
    "    \n",
    " \n",
    "    plt.title('MAPE Comparison Across Lead Times and Models')\n",
    "    plt.xlabel('Leadtime')\n",
    "    plt.ylabel('MAAPE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name in masecompare['Model'].unique():\n",
    "        subset = masecompare[masecompare['Model'] == model_name]\n",
    "        plt.plot(subset['Leadtime'], subset['MAE'], label=model_name, marker='o')\n",
    "    \n",
    "   \n",
    "    plt.title('MAE Comparison Across Lead Times and Models')\n",
    "    plt.xlabel('Leadtime')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return masecompare,compare\n",
    "# Call the function\n",
    "blended,residuals_blended=blended_pca(shapE=True,residual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_blended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning for experiment 3\n",
    "# Tuning with pca in each fold and pca separately for weather and capacity\n",
    "def tuning_blended(df, n_components=2):\n",
    "   \n",
    "\n",
    "    # Initialize models\n",
    "    models = [ SVR(), Ridge(),xgb.XGBRegressor(enable_categorical=True)]\n",
    "    scaler = RobustScaler()\n",
    "    # Set up TimeSeriesSplit for cross-validation\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    best_params = {model.__class__.__name__: {} for model in models}\n",
    "    for frame in frames:\n",
    "        train,test,validation=train_test_validation(df=frame)\n",
    "        y_train = train['Occupancy']\n",
    "        X_train = train.drop(columns=['Occupancy'])\n",
    "\n",
    "        y_val=validation['Occupancy']\n",
    "        X_val=validation.drop(columns=['Occupancy'])\n",
    "            #Scaling all non categorical features\n",
    "        X_train[scale_cols] = scaler.fit_transform(X_train[scale_cols])\n",
    "        X_val[scale_cols] = scaler.transform(X_val[scale_cols])\n",
    "        #Apply pca\n",
    "        pca_total = PCA(n_components=n_components)\n",
    "        X_train_pca = pd.DataFrame(pca_total.fit_transform(X_train[scale_cols]), columns=[f'PC_{i+1}' for i in range(n_components)])\n",
    "        X_train = pd.concat([X_train_pca.reset_index(drop=True), X_train[cat_cols].reset_index(drop=True)], axis=1)\n",
    "        \n",
    "        X_val_pca = pd.DataFrame(pca_total.transform(X_val[scale_cols]), columns=[f'PC_{i+1}' for i in range(n_components)])\n",
    "        X_val = pd.concat([X_val_pca.reset_index(drop=True), X_val[cat_cols].reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "        for model in models:\n",
    "            print(f\"\\nTuning Model: {model.__class__.__name__}\")\n",
    "            \n",
    "            # Parameter grid\n",
    "            if isinstance(model, xgb.XGBRegressor):\n",
    "                param_grid = {'n_estimators': [100, 200, 500], 'max_depth': [3, 5, 7,14], 'learning_rate': [0.001, 0.01, 0.1]}\n",
    "            elif isinstance(model, SVR):\n",
    "                param_grid = {'C': [0.1, 1, 10], 'epsilon': [0.01, 0.1, 0.2], 'kernel': ['rbf']}\n",
    "            else:\n",
    "                param_grid = {'alpha': [0, 0.1, 1, 3, 5]}\n",
    "\n",
    "            # Set up TimeSeriesSplit for cross-validation\n",
    "            tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "            # Initialize GridSearchCV with TimeSeriesSplit\n",
    "            grid_search = GridSearchCV(estimator=model, \n",
    "                                    param_grid=param_grid,\n",
    "                                    scoring='neg_mean_absolute_percentage_error',  #MAAPE for scoring\n",
    "                                    cv=tscv,\n",
    "                                    n_jobs=-1)\n",
    "            \n",
    "            # Fit the grid search model\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            # Get the best parameters and best score\n",
    "            best_params = grid_search.best_params_\n",
    "                \n",
    "            # Initialize the model with the best parameters\n",
    "            best_model = model.set_params(**best_params).fit(X_train, y_train)\n",
    "\n",
    "            # Fit the best model \n",
    "            y_val_pred = best_model.predict(X_val)\n",
    "            mape=np.round(mean_absolute_percentage_error(y_val, y_val_pred), 3)\n",
    "            \n",
    "            print(f\"Best Parameters for Leadtime {frame['Leadtime'].max()} for {model.__class__.__name__}:\", best_params)\n",
    "            print(\"Best Validation MAPE Score:\", mape)\n",
    "\n",
    "tuning_blended(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing scaling with unscaled best models\n",
    "print('Separate PCA')\n",
    "print(separate)\n",
    "print('Blended PCA')\n",
    "print(blended)\n",
    "print('Common PCA best')\n",
    "best_pca=plot_best_model_approach(blended,separate ,xp3=True)\n",
    "print(best_pca.sort_values(by='Model'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing all models and trainig approaches\n",
    "all_df=pd.concat([unscaled,separate,scaled_model,blended,no_weather],ignore_index=True)\n",
    "def best_model(all_df=all_df):\n",
    "    xgb_df = all_df[all_df['Model'] == 'XGBRegressor']\n",
    "    svr_df = all_df[all_df['Model'] == 'SVR']\n",
    "    ridge_df = all_df[all_df['Model'] == 'Ridge']\n",
    "\n",
    "    # XGBRegressor\n",
    "    xgb_df = xgb_df.sort_values(by='MAE')\n",
    "    xgb_best_mae = xgb_df.drop_duplicates(subset=['Leadtime'])\n",
    "    print('Best MAE')\n",
    "    print(xgb_best_mae)\n",
    "    \n",
    "    xgb_df = xgb_df.sort_values(by='RMSE')\n",
    "    xgb_best_rmse = xgb_df.drop_duplicates(subset=['Leadtime'])\n",
    "    print('Best RMSE')\n",
    "    print(xgb_best_rmse)\n",
    "    \n",
    "    xgb_df = xgb_df.sort_values(by='MAPE')\n",
    "    xgb_best_maape = xgb_df.drop_duplicates(subset=['Leadtime'])\n",
    "    print('Best MAPE')\n",
    "    print(xgb_best_maape)\n",
    "    print('')\n",
    "    \n",
    "    # SVR\n",
    "    svr_df = svr_df.sort_values(by='MAE')\n",
    "    svr_best_mae = svr_df.drop_duplicates(subset=['Leadtime'])\n",
    "    print('Best MAE')\n",
    "    print(svr_best_mae)\n",
    "    \n",
    "    svr_df = svr_df.sort_values(by='RMSE')\n",
    "    svr_best_rmse = svr_df.drop_duplicates(subset=['Leadtime'])\n",
    "    print('Best RMSE')\n",
    "    print(svr_best_rmse)\n",
    "    \n",
    "    svr_df = svr_df.sort_values(by='MAPE')\n",
    "    svr_best_maape = svr_df.drop_duplicates(subset=['Leadtime'])\n",
    "    print('Best MAPE')\n",
    "    print(svr_best_maape)\n",
    "    print('')\n",
    "    \n",
    "    # Ridge\n",
    "    ridge_df = ridge_df.sort_values(by='MAE')\n",
    "    ridge_best_mae = ridge_df.drop_duplicates(subset=['Leadtime'])\n",
    "    print('Best MAE')\n",
    "    print(ridge_best_mae)\n",
    "    \n",
    "    ridge_df = ridge_df.sort_values(by='RMSE')\n",
    "    ridge_best_rmse = ridge_df.drop_duplicates(subset=['Leadtime'])\n",
    "    print('Best RMSE')\n",
    "    print(ridge_best_rmse)\n",
    "    \n",
    "    ridge_df = ridge_df.sort_values(by='MAPE')\n",
    "    ridge_best_maape = ridge_df.drop_duplicates(subset=['Leadtime'])\n",
    "    print('Best MAPE')\n",
    "    print(ridge_best_maape)\n",
    "    print('')\n",
    "best_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df=pd.concat([separate,blended],ignore_index=True)\n",
    "best_model(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing all models and trainig approaches except the no_weather one\n",
    "all_df=pd.concat([unscaled,separate,scaled_model,blended],ignore_index=True)\n",
    "best_model(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_plots(df):\n",
    "\n",
    "\n",
    "    all_xgb = df[df['Model'] == 'XGBRegressor']\n",
    "    all_ridge = df[df['Model'] == 'ridge regression']\n",
    "    all_svr = df[df['Model'] == 'SVR']\n",
    "    frames = [all_xgb, all_ridge, all_svr]\n",
    "    \n",
    "    # Define colors for each lead time\n",
    "    lead_colors = {1: 'blue', 5: 'orange', 7: 'green', 14: 'purple'}\n",
    "    \n",
    "    # Mapping approaches to numeric positions\n",
    "    approaches = ['Unscaled', 'Separate', 'Scaled', 'Blended']\n",
    "    approach_positions = {approach: i for i, approach in enumerate(approaches)}\n",
    "    \n",
    "    # Threshold for small differences\n",
    "    threshold = 0.003\n",
    "\n",
    "    for frame in frames:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Use a set to track which lead times have been added to the legend\n",
    "        used_leads = set()\n",
    "        \n",
    "        for approach in approaches:\n",
    "            temp_df = frame[frame['Approach'] == approach]\n",
    "            if temp_df.empty:\n",
    "                continue\n",
    "            \n",
    "            x_position = approach_positions[approach]\n",
    "            \n",
    "            # Sort the DataFrame by MAE for this approach\n",
    "            temp_df = temp_df.sort_values(by='MAE').reset_index(drop=True)\n",
    "            \n",
    "            # Alternate offsets for points based on the threshold\n",
    "            last_y = None\n",
    "            offset_sign = -6  \n",
    "            \n",
    "            for i, (y, lead) in enumerate(zip(temp_df['MAE'], temp_df['Leadtime'])):\n",
    "                if last_y is not None and abs(y - last_y) < threshold:\n",
    "                    offset = offset_sign * 0.05\n",
    "                    align = 'right' if offset_sign == -1 else 'left'\n",
    "                    offset_sign *= -.5  # Alternate sign\n",
    "                else:\n",
    "                    offset = 0.2\n",
    "                    align = 'center'\n",
    "                \n",
    "                last_y = y\n",
    "                \n",
    "                # Only add a label for the legend if the lead time hasn't been added yet\n",
    "                label = f'Leadtime {lead}' if lead not in used_leads else \"\"\n",
    "                if label:\n",
    "                    used_leads.add(lead)\n",
    "                \n",
    "                plt.scatter(x_position, y, color=lead_colors[lead], label=label)\n",
    "                plt.text(x_position + offset, y, f'{y:.3f}', color=lead_colors[lead], ha=align, va='center', fontsize=8)\n",
    "        \n",
    "        # Adjust x-axis ticks and labels\n",
    "        plt.xticks(range(len(approaches)), approaches)\n",
    "        plt.title(f\"MAE for {frame['Model'].iloc[0]}\")\n",
    "        plt.xlabel(\"Approach\")\n",
    "        plt.ylabel(\"MAE\")\n",
    "        plt.margins(x=0.2, y=0.2)\n",
    "        # Position legend outside the plot to the right\n",
    "        plt.legend(title=\"Forecast horizon\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()  # Adjust layout to make room for the legend\n",
    "        plt.show()\n",
    "\n",
    "    for frame in frames:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Use a set to track which lead times have been added to the legend\n",
    "        used_leads = set()\n",
    "        \n",
    "        for approach in approaches:\n",
    "            temp_df = frame[frame['Approach'] == approach]\n",
    "            if temp_df.empty:\n",
    "                continue\n",
    "            \n",
    "            x_position = approach_positions[approach]\n",
    "            \n",
    "            # Sort the DataFrame by MAE for this approach\n",
    "            temp_df = temp_df.sort_values(by='RMSE').reset_index(drop=True)\n",
    "            \n",
    "            # Alternate offsets for points based on the threshold\n",
    "            last_y = None\n",
    "            offset_sign = -6  # Start with -1 for alternating logic\n",
    "            \n",
    "            for i, (y, lead) in enumerate(zip(temp_df['RMSE'], temp_df['Leadtime'])):\n",
    "                if last_y is not None and abs(y - last_y) < threshold:\n",
    "                    offset = offset_sign * 0.05\n",
    "                    align = 'right' if offset_sign == -1 else 'left'\n",
    "                    offset_sign *= -.5  # Alternate sign\n",
    "                else:\n",
    "                    offset = 0.2\n",
    "                    align = 'center'\n",
    "                \n",
    "                last_y = y\n",
    "                \n",
    "                # Only add a label for the legend if the lead time hasn't been added yet\n",
    "                label = f'Leadtime {lead}' if lead not in used_leads else \"\"\n",
    "                if label:\n",
    "                    used_leads.add(lead)\n",
    "                \n",
    "                plt.scatter(x_position, y, color=lead_colors[lead], label=label)\n",
    "                plt.text(x_position + offset, y, f'{y:.3f}', color=lead_colors[lead], ha=align, va='center', fontsize=8)\n",
    "        \n",
    "        # Adjust x-axis ticks and labels\n",
    "        plt.xticks(range(len(approaches)), approaches)\n",
    "        plt.title(f\"RMSE for {frame['Model'].iloc[0]}\")\n",
    "        plt.xlabel(\"Approach\")\n",
    "        plt.ylabel(\"RMSE\")\n",
    "        plt.margins(x=0.2, y=0.2)\n",
    "        # Position legend outside the plot to the right\n",
    "        plt.legend(title=\"Forecast horizon\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()  # Adjust layout to make room for the legend\n",
    "        plt.show()\n",
    "\n",
    "    for frame in frames:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Use a set to track which lead times have been added to the legend\n",
    "        used_leads = set()\n",
    "        \n",
    "        for approach in approaches:\n",
    "            temp_df = frame[frame['Approach'] == approach]\n",
    "            if temp_df.empty:\n",
    "                continue\n",
    "\n",
    "            x_position = approach_positions[approach]\n",
    "\n",
    "            # Sort the DataFrame by MAPE for this approach\n",
    "            temp_df = temp_df.sort_values(by='MAPE').reset_index(drop=True)\n",
    "\n",
    "            # Alternate offsets for points based on the threshold\n",
    "            last_y = None\n",
    "            offset_sign = -6  # Start with -1 for alternating logic\n",
    "            height_offset = 0\n",
    "            for i, (y, lead) in enumerate(zip(temp_df['MAPE'], temp_df['Leadtime'])):\n",
    "                # Check if current and previous y-values are close enough\n",
    "                if last_y is not None and abs(y - last_y) < threshold:\n",
    "                    offset = offset_sign * 0.05\n",
    "                    align = 'right' if offset_sign == -1 else 'left'\n",
    "                    offset_sign *= -0.5  # Alternate sign\n",
    "                else:\n",
    "                    offset = 0.2\n",
    "                    align = 'center'\n",
    "                \n",
    "                last_y = y\n",
    "\n",
    "                # Check if model is SVR, lead is 5, and the approach is Blended\n",
    "                if 'SVR' in frame['Model'].values and lead == 5 and 'Blended' in frame['Approach'].values:\n",
    "                    height_offset = 0.002  # Apply height offset only for this specific condition\n",
    "\n",
    "                # Only add a label for the legend if the lead time hasn't been added yet\n",
    "                label = f'Leadtime {lead}' if lead not in used_leads else \"\"\n",
    "                if label:\n",
    "                    used_leads.add(lead)\n",
    "\n",
    "                plt.scatter(x_position, y, color=lead_colors[lead], label=label)\n",
    "                plt.text(x_position + offset, y + height_offset, f'{y:.3f}', color=lead_colors[lead], ha=align, va='center', fontsize=8)\n",
    "\n",
    "        # Adjust x-axis ticks and labels\n",
    "        plt.xticks(range(len(approaches)), approaches)\n",
    "        plt.title(f\"MAPE for {frame['Model'].iloc[0]}\")\n",
    "        plt.xlabel(\"Approach\")\n",
    "        plt.ylabel(\"MAPE\")\n",
    "        plt.margins(x=0.2, y=0.2)\n",
    "        # Position legend outside the plot to the right\n",
    "        plt.legend(title=\"Forecast horizon\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()  # Adjust layout to make room for the legend\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "performance_plots(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(residuals_scale[residuals_scale['extreme']==True]['Date visit'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_scale[residuals_scale['extreme']==True].head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(residuals_separate[residuals_separate['extreme']==True]['Date visit']))\n",
    "print(residuals_separate[residuals_separate['extreme']==True]['difference'].mean())\n",
    "residuals_separate[residuals_separate['extreme']==True].head(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(residuals_blended[residuals_blended['extreme']==True]['Date visit']))\n",
    "print(residuals_blended[residuals_blended['extreme']==True]['difference'].mean())\n",
    "residuals_blended[residuals_blended['extreme']==True].head(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(df,extensive=False):\n",
    "\n",
    "     # Define colors for each lead time\n",
    "     #Can be made different, but they will just overcolor the previous one\n",
    "     #opacity can be set at varying rates but it makes interpretation more difficult\n",
    "     #I keep the lead time distinction to have the percentage for each horizon included in the plot\n",
    "    lead_colors = {1: 'orange', 5: 'orange', 7: 'orange', 14: 'orange'}\n",
    "    alphas={1:0.9,5:0.7,7:0.5,14:0.3}\n",
    "    for algo in np.unique(df['Model']):\n",
    "        filter = df[df['Model'] == algo]\n",
    "        std_dev = filter.groupby('Leadtime')['difference'].std()\n",
    "        median=filter.groupby('Leadtime')['difference'].median()\n",
    "        print('Median')\n",
    "        print(filter.groupby('Leadtime')['difference'].median())\n",
    "        print(filter.groupby('Leadtime')['difference'].mean())\n",
    "        impossible = filter['extreme'].sum()/filter.shape[0]*100\n",
    "        #Plot the differences for the selected model and lead time\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(filter['Leadtime'], filter['difference'], marker='o', color='b')\n",
    "        #plt.plot(std_dev.index, std_dev.values, marker='x', linestyle='--', color='r', label='Standard Deviation')\n",
    "        plt.scatter(median.index,median.values,label=\"Median\",color='r')\n",
    "        plt.xlabel('Forecast horizon')\n",
    "        plt.ylabel('Difference (Truth - Predictions)')\n",
    "        plt.title(f'Residuals for {algo} with {np.round(impossible,2)}% of predictions above 2 standard deviations')\n",
    "        plt.show()\n",
    "        \n",
    "        if extensive == True:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            temp_df=filter[filter['Leadtime']==1]\n",
    "            plt.plot(temp_df['Date visit'],temp_df['true'],label='True occupancy',color='b')\n",
    "            \n",
    "            plt.title(f'True occupancy and extreme {algo} residuals')\n",
    "            \n",
    "            model_extreme=filter[filter['extreme']==True]\n",
    "            for lead in np.unique(model_extreme['Leadtime']):\n",
    "                #calculates extreme value percentage for each forecast horizon\n",
    "                impossible = np.round(model_extreme[model_extreme['Leadtime']==lead]['extreme'].sum()/filter.shape[0]*100,2)\n",
    "                #Drops duplicates for same day, same horizon to declutter plotting\n",
    "                model_extreme2=model_extreme.drop_duplicates(subset=['Leadtime','Date visit'])\n",
    "                \n",
    "                plt.scatter(model_extreme2['Date visit'],model_extreme2['predicted'],color=lead_colors[lead], label=f'Forecast horizon {lead} with {impossible}% extreme residuals',marker='.')\n",
    "                plt.legend()\n",
    "            plt.show()\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis(residuals_naive,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis(residuals_no_weather,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis(residuals_unscaled,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis(residuals_scale,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis(residuals_separate,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis(residuals_blended,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
